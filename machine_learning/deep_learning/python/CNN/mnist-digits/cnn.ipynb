{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Architechure:</b><br>\n",
    "    Convolution((5,5),32) -> MaxPool((2,2),padding=same) -> Convolution((5,5),64) -> MaxPool((2,2),padding=same) -> DenseLayer , Dropout(0.5) -> output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,MaxPool2D,Conv2D,Dropout\n",
    "from keras.layers.core import Dense,Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv('./mnistd/train.csv')\n",
    "data_test = pd.read_csv('./mnistd/test.csv')\n",
    "\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train['label'] \n",
    "data_train = data_train.drop('label',axis=1)\n",
    "x_train = data_train.values\n",
    "x_test = data_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28, 1) (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape([-1,28,28,1])\n",
    "x_test = x_test.reshape([-1,28,28,1])\n",
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255 #normalising the image\n",
    "x_test = x_test/255\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label is: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20b0734b978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show(image_num):\n",
    "    plt.imshow(1-x_train[image_num-1][:, :, 0], cmap='gray')\n",
    "    print(\"the label is:\",y_train[image_num-1])\n",
    "\n",
    "image_num = 1\n",
    "show(image_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), padding=\"same\", input_shape=[28, 28, 1])) #Convolution Layer\n",
    "model.add(MaxPool2D((2,2))) # Pooling Layer\n",
    "model.add(Conv2D(64, (5, 5), padding=\"same\"))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5)) #Adding Dropout\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39480 samples, validate on 2520 samples\n",
      "Epoch 1/4\n",
      " - 179s - loss: 0.1855 - acc: 0.9439 - val_loss: 0.0735 - val_acc: 0.9782\n",
      "Epoch 2/4\n",
      " - 185s - loss: 0.0653 - acc: 0.9790 - val_loss: 0.0457 - val_acc: 0.9853\n",
      "Epoch 3/4\n",
      " - 187s - loss: 0.0444 - acc: 0.9856 - val_loss: 0.0351 - val_acc: 0.9857\n",
      "Epoch 4/4\n",
      " - 184s - loss: 0.0376 - acc: 0.9879 - val_loss: 0.0284 - val_acc: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b07359128>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_split=0.06, batch_size=100, epochs=4, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict_classes(x_test)\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_id = numpy.array([[i] for i in range(1,28001)])\n",
    "y_test = y_test.reshape((28000,1))\n",
    "y_test = numpy.concatenate((img_id,y_test),axis=1)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Got an accuracy of of 0.982 on test set<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
