## k-Nearest Neighbours
The k-Nearest Neighbours (k-NN) algorithm is a supervised machine learning algorithm that can used for classification and regression.
In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:
 * In k-NN classification, the output is a class membership. An object is classified by a majority vote of its neighbours, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbour.
 * In k-NN regression, the output is the property value for the object. This value is the average of the values of its k nearest neighbours.

#### A graphical explanation of KNN
![Image of KNN](https://cdn-images-1.medium.com/max/960/0*Sk18h9op6uK9EpT8.)

#### Further reference:
https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm
